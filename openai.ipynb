{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required libraries are installed.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import importlib\n",
    "\n",
    "required_libraries = [\n",
    "    'torch', 'pyaudio', 'wave', 'numpy', \n",
    "    'transformers', 'scipy'\n",
    "]\n",
    "\n",
    "conda_command = 'conda install'\n",
    "pip_command = 'pip install'\n",
    "\n",
    "for library in required_libraries:\n",
    "    try:\n",
    "        importlib.import_module(library)\n",
    "    except ImportError:\n",
    "        print(f'{library} not found. Installing...')\n",
    "        if 'conda' in subprocess.run(['which', 'python'], capture_output=True, text=True).stdout:\n",
    "            subprocess.run([conda_command, library, '-y'])\n",
    "        else:\n",
    "            subprocess.run([pip_command, library])\n",
    "\n",
    "print('All required libraries are installed.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import                                  torch\n",
    "import                                  pyaudio\n",
    "import                                  wave\n",
    "import                                  numpy                                               as  np\n",
    "from    transformers            import  WhisperProcessor, WhisperForConditionalGeneration\n",
    "from    scipy.io                import  wavfile\n",
    "from    transformers            import  pipeline\n",
    "# Parameters for audio input\n",
    "FORMAT = pyaudio.paInt16   # Format of audio samples\n",
    "CHANNELS = 1               # Number of audio channels (1 for mono, 2 for stereo)\n",
    "RATE = 16000               # Sampling rate (samples per second)\n",
    "CHUNK = 1024               # Number of frames per buffer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def encode_to_x265(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Encode a video file to x265 format using FFmpeg.\n",
    "\n",
    "    :param input_file: Input video file path.\n",
    "    :param output_file: Output file path for the encoded video.\n",
    "    \"\"\"\n",
    "    # Use FFmpeg with libx265 to encode the video file\n",
    "    ffmpeg_cmd = f'ffmpeg -i  \"{input_file}\" -vn -acodec pcm_s16le -ar 16000 -ac 1 \"{output_file}\"'\n",
    "    subprocess.run(ffmpeg_cmd, shell=True)\n",
    "\n",
    "def write_text_to_file(filename, text):\n",
    "    \"\"\"\n",
    "    Write a text string to a file.\n",
    "\n",
    "    :param filename: The name of the file to write to.\n",
    "    :param text: The text string to write to the file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, 'w') as file:\n",
    "            file.write(text)\n",
    "        print(f\"Text has been written to {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_wave_file(cached_audio, p, AMPLIFICATION_FACTOR=10, output_file=\"cached_audio.wav\"):\n",
    "    \"\"\"\n",
    "    Save the cached audio data to a WAV file.\n",
    "\n",
    "    Args:\n",
    "        cached_audio (numpy.ndarray): The audio data to be saved.\n",
    "        p (pyaudio.PyAudio): PyAudio instance.\n",
    "        AMPLIFICATION_FACTOR (int, optional): Amplification factor for the audio. Default is 10.\n",
    "        output_file (str, optional): Output file path. Default is \"cached_audio.wav\".\n",
    "    \"\"\"\n",
    "    # Save the cached audio to a WAV file\n",
    "    with wave.open(output_file, \"wb\") as wf:\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "        wf.setframerate(RATE)\n",
    "        wf.writeframes((cached_audio * AMPLIFICATION_FACTOR).tobytes())\n",
    "    print(f\"Saved cached audio to {output_file}\")\n",
    "\n",
    "\n",
    "def record_audio():\n",
    "    \"\"\"\n",
    "    Record audio from the microphone.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Numpy array of recorded audio and PyAudio instance.\n",
    "    \"\"\"\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "    # Initialize an empty list to store audio data\n",
    "    audio_cache = []\n",
    "    try:\n",
    "        print(\"Recording... (Press Ctrl+C to stop)\")\n",
    "        while True:\n",
    "            # Read audio data from the microphone\n",
    "            data = stream.read(CHUNK)\n",
    "\n",
    "            # Convert the binary audio data to a numpy array\n",
    "            audio_sample = np.frombuffer(data, dtype=np.int16)\n",
    "\n",
    "            # Append the audio sample to the cache\n",
    "            audio_cache.append(audio_sample)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Recording stopped.\")\n",
    "\n",
    "    # Close the audio stream and PyAudio instance\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    # Convert the list of audio samples into a numpy array\n",
    "    return np.concatenate(audio_cache), p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Audio Extact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'ffmpeg -i ./Conv_1.\\ Course\\ content_720p_x265.mp4 -vn -acodec pcm_s16le -ar 16000 -ac 1  ./output.wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Audio-to-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc6d938ab557466e8b2276b614cd6c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/3.06G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://huggingface.co/openai/whisper-large-v2\n",
    "# https://huggingface.co/jonatasgrosman/wav2vec2-large-xlsr-53-english\n",
    "\n",
    "index = -1\n",
    "modelss = [\n",
    "            # \"openai/whisper-tiny\",   #39m params useless\n",
    "            \"openai/whisper-base\",   #74m params\n",
    "            \"openai/whisper-small\",  #244m params very well\n",
    "            \"openai/whisper-medium\", #769m params\n",
    "           ]\n",
    "# load model and processor\n",
    "processor = WhisperProcessor.from_pretrained(modelss[index])\n",
    "model = WhisperForConditionalGeneration.from_pretrained(modelss[index]).to('cuda')\n",
    "model.config.forced_decoder_ids = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm.c:2666:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2666:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2666:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_route.c:877:(find_matching_chmap) Found no matching channel map\n",
      "ALSA lib pcm_route.c:877:(find_matching_chmap) Found no matching channel map\n",
      "ALSA lib pcm_route.c:877:(find_matching_chmap) Found no matching channel map\n",
      "ALSA lib pcm_route.c:877:(find_matching_chmap) Found no matching channel map\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording... (Press Ctrl+C to stop)\n",
      "Recording stopped.\n",
      "Saved cached audio to cached_audio.wav\n"
     ]
    }
   ],
   "source": [
    "# audio_cache,p = record_audio()\n",
    "# save_wave_file(audio_cache,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplerat1, data1 = wavfile.read('output.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1= data1/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hass memory of 27 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ysn/anaconda3/envs/torch3.9/lib/python3.9/site-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"english\", task=\"transcribe\")\n",
    "text = ''\n",
    "\n",
    "S_rate = 16000\n",
    "for index in range(len(data1)//(25*S_rate)):\n",
    "    input_features = processor(data1[(S_rate*index*25):(S_rate*(index+1)*25)], sampling_rate=S_rate, return_tensors=\"pt\").input_features.to('cuda')\n",
    "    predicted_ids = model.generate(input_features)\n",
    "    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
    "    text += transcription[0] + ' '\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Hello and welcome to the course, Generative Adversary Network School with guides. My name is Jones, I am the founder of the AI Experts Academy, which is an internship online platform with a lot of courses on artificial intelligence and machine learning.  Hello, I'm going to teach all the lectures of this course. Now I'm going to show you the contents that will be covered. First, you are going to learn some interesting applications of games, as well as a brief introduction to the intuition of how it works. Then we are going to move on.  The practical implementations. The first two implementations that you are going to learn are DC Game and W Game. They are the same placed ones. I have opened the first implementation about Deep Convolutional Games. As you can see, all implementations will be...  Don't step by step using Google Cloud online, so you don't need to worry about installing all the libraries on your machine. Another advantage about using Google Cloud is that it allows you to use a GPU, so the training process of the game  This will be faster. You can see all the codes that will be implemented step by step. The first project is the most classic, and if you already ever taken a course on this subject, probably you have implemented this project. The idea is to create the digits from zero.  As we can see here, then we are going to evolve to a more advanced architecture which is the booyougan. We can see here all the animations that you are going to learn step by step. We can see here some results. We are going to use the same data set.  The goal is to generate the digits, see that results are much better if compared to the other architecture. In this first project, we are going just to see this is more application to generate hand written digits. Something interesting is that these digits  Don't exist in the world or they are not in the concept they were created by them. Then you are going to move on to more interesting applications. You are going to learn true architectures of C-game, which means conditional game, pixel to pixel cycle.  One of the projects will be to generate images in the map format. For example, we can see here the input image, which is a separate image. This is the real image, similar to Google Maps. The goal is to generate the image in the map.  We set to begin the satellite image and it will generate the cross-border version in the map for months. We can see here some other examples. In this case today, we are just training the game for a few ebooks. However, if you train for more time...  You will get better results. You are going to learn how to implement the PIX2PIX architecture from scratch since the creation of the generator, the discriminator and all other steps. There are some other applications. For example, we send this  Edge is to be done and it will create the corresponding image of the building. Other application is to convert all the edges into foes. As we can see here, we are sending images of foes and it will generate something similar to the building.  After we are going to implement the cycle game architecture, the case study will be to convert images of apples into images of oranges. We can see here some examples. The apples converted into oranges.  There are some other interesting applications such as transforming a horse into a zebra. We can see here two more examples. We are also going to implement a style transfer. For example, we can see here some images and this is the output.  We are changing the style of the image. We can use the styles of famous artists. We can see more examples here. We have a lot of nice effects when we transfer the style from one image to another. The next architectures.  You are going to learn R-S-R-N, N-E-S-R-N, which means super resolution dance. The idea of this technique is to send to the network a low resolution image and it will output a high resolution one.  For example, we can send this image, and the result will be like this. See that it really can increase the resolution with interesting results. We can see this other one, see that some parts of the image are blurred, and when we send it again, we have the  It is a very interesting result since it is possible to increase the resolution. We can also see this other image. There are some noises in the image near the head and at the background when we apply a super resolution algorithm the result is very interesting.  We are increasing resolution and also removing the noise. This application is very interesting because you can use it with your own voice. The next one is the style game. This type of game is used to generate faces of...  We can see here some examples, and the interesting about it is that all these people don't exist in the real world. They were generated by the God. It is very hard to say if these people are real or not real.  Text architecture is VQ.com's clip. It is used to convert text into image. So you can type any text you want and it will generate the cross-point image. We are going to send the following text to the clip.  A fantasy kingdom! This video will show the results that will be generated. The game starts with a random image and it keeps improving until we get results similar to this one. The idea is that the game will read the text.  the image that corresponds to the text. The next architecture is Big Data. You will be able to generate images of over one thousand different objects. We can see here some images of castles,  That have been generated by the game. Some images of headers and also flowers. As I said, it is possible to generate one thousand different objects. Just try again, all these images actually don't exist in the real world.  were generated by the game. The next architecture is GFP game. They are used for old photo restoration. You can see this photo that was taken with an old camera. We send it to the algorithm and we get this result. See?  that the faces are in high resolution we can see the side by side comparison the entry image this is the original photo and after applying the algorithm here we can see the images of the bills it has very interesting results  The application is interesting because you can send your own photos. If you have your own photos, you can send to the game and it will restore it. The next architecture is boundless. The goal is to complete missing parts of images. For example,  Here is the original image, we send to the neural network the masked image, the game does not have access to the gray part of the image here, we send only a part of the image, and at the end it is able to complete the results of the game.  Very interesting, we can see that this part of the sun was correctly completed and also the mountain. Of course, the results will not be the same as the original image, since the game needs to guess what comes next. Finally, the last architecture.  is seen so it can be used to create deepfakes or exchange faces between images. We have this image and this other one. So the goal is to copy this face to this other image. And the idea is to keep all of them.  All the background information. This is the result. We can see that the algorithm could correctly exchange the faces. What is interesting is that it keeps all the original information such as the hair and the blue color on the face. If you want you can perform the...  Test with your own photos. Finally, you will also learn how to apply kin in videos. At the end of the course, there are two additional contents. The intuition about artificial neural networks and also about convolutional neural networks.  Content is very important, especially for the first implementations. It is recommended that you take these lectures. Regarding prerequisites, it is recommended that you know about programming logic, basic Python programming, and knowledge about neural networks.  Is this variable not mandatory? Because there are the additional contents that recap all the intuition about this topic. Something important is that you are going to learn only the basic intuition about the algorithms. Don't expect too much about the mathematical background.  The idea is just to show some basic intuition and then we are going to move on to the implementations. The focus of the course is on implementing the projects. And something also very important, there are many other types of games they are evolving very quickly.  Maybe when you take this course, there are some other new architectures that are not covered. The idea of the course is to cover all the basics about games, especially the most used architectures. We hope you have a great course. In the next two lectures, you are going to learn the basics of the game. \""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'total_lenght' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(text\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m:(total_lenght\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m3\u001b[39m)])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'total_lenght' is not defined"
     ]
    }
   ],
   "source": [
    "' '.join(text.split(' ')[0:(total_lenght//3)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello and welcome to the course, Generative Adversary Network School with guides', 'My name is Jones, I am the founder of the AI Experts Academy, which is an internship online platform with a lot of courses on artificial intelligence and machine learning', \"Hello, I'm going to teach all the lectures of this course\", \"Now I'm going to show you the contents that will be covered\", 'First, you are going to learn some interesting applications of games, as well as a brief introduction to the intuition of how it works', 'Then we are going to move on', 'The practical implementations', 'The first two implementations that you are going to learn are DC Game and W Game', 'They are the same placed ones', 'I have opened the first implementation about Deep Convolutional Games', 'As you can see, all implementations will be', \"Don't step by step using Google Cloud online, so you don't need to worry about installing all the libraries on your machine\", 'Another advantage about using Google Cloud is that it allows you to use a GPU, so the training process of the game  This will be faster', 'You can see all the codes that will be implemented step by step', 'The first project is the most classic, and if you already ever taken a course on this subject, probably you have implemented this project', 'The idea is to create the digits from zero', 'As we can see here, then we are going to evolve to a more advanced architecture which is the booyougan', 'We can see here all the animations that you are going to learn step by step', 'We can see here some results', 'We are going to use the same data set', 'The goal is to generate the digits, see that results are much better if compared to the other architecture', 'In this first project, we are going just to see this is more application to generate hand written digits', \"Something interesting is that these digits  Don't exist in the world or they are not in the concept they were created by them\", 'Then you are going to move on to more interesting applications', 'You are going to learn true architectures of C-game, which means conditional game, pixel to pixel cycle', 'One of the projects will be to generate images in the map format', 'For example, we can see here the input image, which is a separate image', 'This is the real image, similar to Google Maps', 'The goal is to generate the image in the map', 'We set to begin the satellite image and it will generate the cross-border version in the map for months', 'We can see here some other examples', 'In this case today, we are just training the game for a few ebooks', 'However, if you train for more time', 'You will get better results', 'You are going to learn how to implement the PIX2PIX architecture from scratch since the creation of the generator, the discriminator and all other steps', 'There are some other applications', 'For example, we send this  Edge is to be done and it will create the corresponding image of the building', 'Other application is to convert all the edges into foes', 'As we can see here, we are sending images of foes and it will generate something similar to the building', 'After we are going to implement the cycle game architecture, the case study will be to convert images of apples into images of oranges', 'We can see here some examples', 'The apples converted into oranges', 'There are some other interesting applications such as transforming a horse into a zebra', 'We can see here two more examples', 'We are also going to implement a style transfer', 'For example, we can see here some images and this is the output', 'We are changing the style of the image', 'We can use the styles of famous artists', 'We can see more examples here', 'We have a lot of nice effects when we transfer the style from one image to another', 'The next architectures', 'You are going to learn R-S-R-N, N-E-S-R-N, which means super resolution dance', 'The idea of this technique is to send to the network a low resolution image and it will output a high resolution one', 'For example, we can send this image, and the result will be like this', 'See that it really can increase the resolution with interesting results', 'We can see this other one, see that some parts of the image are blurred, and when we send it again, we have the  It is a very interesting result since it is possible to increase the resolution', 'We can also see this other image', 'There are some noises in the image near the head and at the background when we apply a super resolution algorithm the result is very interesting', 'We are increasing resolution and also removing the noise', 'This application is very interesting because you can use it with your own voice', 'The next one is the style game', 'This type of game is used to generate faces of', \"We can see here some examples, and the interesting about it is that all these people don't exist in the real world\", 'They were generated by the God', 'It is very hard to say if these people are real or not real', 'Text architecture is VQ', \"com's clip\", 'It is used to convert text into image', 'So you can type any text you want and it will generate the cross-point image', 'We are going to send the following text to the clip', 'A fantasy kingdom! This video will show the results that will be generated', 'The game starts with a random image and it keeps improving until we get results similar to this one', 'The idea is that the game will read the text', 'the image that corresponds to the text', 'The next architecture is Big Data', 'You will be able to generate images of over one thousand different objects', 'We can see here some images of castles,  That have been generated by the game', 'Some images of headers and also flowers', 'As I said, it is possible to generate one thousand different objects', \"Just try again, all these images actually don't exist in the real world\", 'were generated by the game', 'The next architecture is GFP game', 'They are used for old photo restoration', 'You can see this photo that was taken with an old camera', 'We send it to the algorithm and we get this result', 'See?  that the faces are in high resolution we can see the side by side comparison the entry image this is the original photo and after applying the algorithm here we can see the images of the bills it has very interesting results  The application is interesting because you can send your own photos', 'If you have your own photos, you can send to the game and it will restore it', 'The next architecture is boundless', 'The goal is to complete missing parts of images', 'For example,  Here is the original image, we send to the neural network the masked image, the game does not have access to the gray part of the image here, we send only a part of the image, and at the end it is able to complete the results of the game', 'Very interesting, we can see that this part of the sun was correctly completed and also the mountain', 'Of course, the results will not be the same as the original image, since the game needs to guess what comes next', 'Finally, the last architecture', 'is seen so it can be used to create deepfakes or exchange faces between images', 'We have this image and this other one', 'So the goal is to copy this face to this other image', 'And the idea is to keep all of them', 'All the background information', 'This is the result', 'We can see that the algorithm could correctly exchange the faces', 'What is interesting is that it keeps all the original information such as the hair and the blue color on the face', 'If you want you can perform the', 'Test with your own photos', 'Finally, you will also learn how to apply kin in videos', 'At the end of the course, there are two additional contents', 'The intuition about artificial neural networks and also about convolutional neural networks', 'Content is very important, especially for the first implementations', 'It is recommended that you take these lectures', 'Regarding prerequisites, it is recommended that you know about programming logic, basic Python programming, and knowledge about neural networks', 'Is this variable not mandatory? Because there are the additional contents that recap all the intuition about this topic', 'Something important is that you are going to learn only the basic intuition about the algorithms', \"Don't expect too much about the mathematical background\", 'The idea is just to show some basic intuition and then we are going to move on to the implementations', 'The focus of the course is on implementing the projects', 'And something also very important, there are many other types of games they are evolving very quickly', 'Maybe when you take this course, there are some other new architectures that are not covered', 'The idea of the course is to cover all the basics about games, especially the most used architectures', 'We hope you have a great course', 'In the next two lectures, you are going to learn the basics of the game']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the regular expression pattern\n",
    "paragraph_pattern = r'\\.'\n",
    "\n",
    "# Your long transcript\n",
    "transcript = text\n",
    "\n",
    "# Split the transcript into paragraphs\n",
    "paragraphs = re.split(paragraph_pattern, transcript)\n",
    "\n",
    "# Optionally, strip leading/trailing whitespace\n",
    "paragraphs = [p.strip() for p in paragraphs]\n",
    "\n",
    "\n",
    "# Using a list comprehension to remove empty strings\n",
    "filtered_list = [item for item in paragraphs if item.strip() != \"\"]\n",
    "\n",
    "print(filtered_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Summurazation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d2e43de25b41a298bfb829a719b887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ed719d1eb74754a475680cc5cc7acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24024e832d57463ab74b5d9697bf1977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65c7a40bbec94d1a9d6f908533c3d5fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d23d1bae55e74188aa229efbb48facf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello and welcome to the course, Generative Adversary Network School with guides My name is Jones, I am the founder of the AI Experts Academy, which is an internship online platform with a lot of courses on artificial intelligence and machine learning Hello, I'm going to teach all the lectures of this course Now I'm going to show you the contents that will be covered First, you are going to learn some interesting applications of games, as well as a brief introduction to the intuition of how it works Then we are going to move on The practical implementations The first two implementations that you are going to learn are DC Game and W Game They are the same placed ones I have opened the first implementation about Deep Convolutional Games As you can see, all implementations will be Don't step by step using Google Cloud online, so you don't need to worry about installing all the libraries on your machine Another advantage about using Google Cloud is that it allows you to use a GPU, so the training process of the game  This will be faster You can see all the codes that will be implemented step by step The first project is the most classic, and if you already ever taken a course on this subject, probably you have implemented this project The idea is to create the digits from zero As we can see here, then we are going to evolve to a more advanced architecture which is the booyougan We can see here all the animations that you are going to learn step by step We can see here some results We are going to use the same data set The goal is to generate the digits, see that results are much better if compared to the other architecture In this first project, we are going just to see this is more application to generate hand written digits Something interesting is that these digits  Don't exist in the world or they are not in the concept they were created by them Then you are going to move on to more interesting applications You are going to learn true architectures of C-game, which means conditional game, pixel to pixel cycle One of the projects will be to generate images in the map format For example, we can see here the input image, which is a separate image This is the real image, similar to Google Maps The goal is to generate the image in the map We set to begin the satellite image and it will generate the cross-border version in the map for months We can see here some other examples In this case today, we are just training the game for a few ebooks However, if you train for more time You will get better results You are going to learn how to implement the PIX2PIX architecture from scratch since the creation of the generator, the discriminator and all other steps There are some other applications For example, we send this  Edge is to be done and it will create the corresponding image of the building Other application is to convert all the edges into foes As we can see here, we are sending images of foes and it will generate something similar to the building\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': \"The course is called Generative Adversary Network School with guides. The first project is the most classic, and if you already ever taken a course on this subject, probably you have implemented this project. All implementations will be Don't step by step using Google Cloud online, so you don't need to worry about installing all the libraries on your machine. Using Google Cloud is that it allows you to use a GPU, so the training process of the game will be faster.\"}]\n"
     ]
    }
   ],
   "source": [
    "print(summarizer(' '.join(filtered_list[0:(len(filtered_list)//3)]) , min_length=90, do_sample=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
